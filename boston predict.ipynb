{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1=[[-1.25916633 -0.22786409 -0.43534138 -2.04768835 -1.66449849 -1.07391399\n",
      "  -1.14066584  0.19093933 -1.45049366 -1.48615221]\n",
      " [-0.71111008 -1.22257403  0.74259885  1.28673071  1.40194101 -0.45567242\n",
      "   0.91003857  0.04315571  1.41115646 -1.63911508]\n",
      " [-0.67141923 -0.7831535   0.54716362  0.34507137 -0.72527282  1.53441322\n",
      "  -0.88839283  0.52979263  1.8872834  -0.39570198]\n",
      " [-0.43479885  2.19043685 -1.67661583 -0.39027786 -0.26665942  1.57105597\n",
      "   0.70787698 -0.38611307  1.10559993 -0.94904729]\n",
      " [-2.28660085  1.43290513 -0.46347523 -0.47390862  0.03117246 -0.63790717\n",
      "   1.6533666  -1.18248942 -0.30873282  0.01972568]\n",
      " [ 0.26312872  0.77884305 -0.60811156 -0.3246083  -0.05058766 -1.23482334\n",
      "   0.32035438  1.60128863 -0.21596585  0.11623108]\n",
      " [ 0.00677877 -0.39537815 -0.54698832 -0.43339434  1.75026129 -0.43382733\n",
      "  -1.46574328 -0.99092234  2.26641733 -0.40109036]\n",
      " [ 0.10282172 -1.58268142  1.46768296 -2.28909464  0.60641069 -0.33221962\n",
      "  -0.30803742 -1.58849152  0.75896534  0.70146657]\n",
      " [ 0.02595481  0.08727417  1.68441167  1.0344745  -0.17342521 -0.16362268\n",
      "  -0.58758415  1.82185632  0.20797325 -0.55146849]\n",
      " [ 0.59759212 -1.53212646  1.33257687  0.34422988  0.98503019 -0.34900853\n",
      "   0.30848516 -0.93860933 -1.3047496  -1.2587681 ]\n",
      " [ 1.06002873 -0.03275617  0.50832031  0.33171193 -1.15954418  1.35306034\n",
      "  -0.89428125  0.29722064 -2.64947388 -1.32255429]\n",
      " [ 0.90398025  0.28281339  0.36424318 -0.63309047  0.00486315  0.39756402\n",
      "  -0.79340119  0.12128774 -0.31993811  1.74471598]\n",
      " [-0.21990094 -1.06241507 -0.01849419 -1.36787549 -1.19649521 -1.01926446\n",
      "  -0.9244235  -0.11644774  1.87100375 -0.00324085]] \n",
      " w2=[[ 0.14570179]\n",
      " [ 0.87399602]\n",
      " [ 0.3526955 ]\n",
      " [ 0.71892462]\n",
      " [ 1.96466634]\n",
      " [ 0.84100904]\n",
      " [-0.21535445]\n",
      " [ 2.23126442]\n",
      " [ 0.07580579]\n",
      " [ 1.11989804]]\n",
      "b1=[2.20624998 2.20624998 2.20624998 2.20624998 2.20624998 2.20624998\n",
      " 2.20624998 2.20624998 2.20624998 2.20624998] \n",
      " b2=[0.67529613]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    使用numpy实现Boston房价预测\n",
    "    Step1 数据加载，来源sklearn中的load_boston\n",
    "    Step2 数据规范化，将X 采用正态分布规范化\n",
    "    Step3 初始化网络\n",
    "    Step4 定义激活函数，损失函数，学习率 epoch\n",
    "    Step5 循环执行：前向传播，计算损失函数，反向传播，参数更新\n",
    "    Step6 输出训练好的model参数，即w1, w2, b1, b2\n",
    "\"\"\" \n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "\n",
    "# 数据加载\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y = data['target']\n",
    "# 将y转化为矩阵的形式\n",
    "y = y.reshape(y.shape[0],1)\n",
    "\n",
    "# 数据规范化\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "\n",
    "\"\"\"\n",
    "    初始化网络参数\n",
    "    定义隐藏层维度，w1,b1,w2,b2\n",
    "\"\"\" \n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "w1 = np.random.randn(n_features, n_hidden)\n",
    "b1 = np.zeros(n_hidden)\n",
    "w2 = np.random.randn(n_hidden, 1)\n",
    "b2 = np.zeros(1)\n",
    "\n",
    "# relu函数\n",
    "def Relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "# 设置学习率\n",
    "learning_rate = 1e-6\n",
    "\n",
    "# 定义损失函数\n",
    "def MSE_loss(y, y_hat):\n",
    "    \"\"\" 这里写你的代码 \"\"\"\n",
    "    return 0.5*np.square(y_hat-y).sum()\n",
    "\n",
    "# 定义线性回归函数\n",
    "def Linear(X, W1, b1):\n",
    "    \"\"\" 这里写你的代码 \"\"\"\n",
    "    return np.dot(X,W1) + b1\n",
    "\n",
    "# 5000次迭代\n",
    "for t in range(5000):\n",
    "    # 前向传播，计算预测值y (Linear->Relu->Linear)\n",
    "    \"\"\" 这里写你的代码 \"\"\"\n",
    "    temp = Linear(X_, w1, b1)\n",
    "    temp_relu = Relu(temp)\n",
    "    y_hat = Linear(temp_relu, w2, b2)\n",
    "\n",
    "    # 计算损失函数, 并输出每次epoch的loss\n",
    "    \"\"\" 这里写你的代码 \"\"\"\n",
    "    loss = MSE_loss(y, y_hat)\n",
    "   # print(loss)\n",
    "\n",
    "    # 反向传播，基于loss 计算w1和w2的梯度\n",
    "    \"\"\" 这里写你的代码 \"\"\" \n",
    "    grad_y_hat = 2.0 * (y_hat - y)\n",
    "    grad_w2 = np.dot(temp_relu.T,grad_y_hat)\n",
    "    grad_b2 = np.sum(grad_y_hat)\n",
    "    grad_temp_relu = np.dot(grad_y_hat, w2.T )\n",
    "    grad_temp = grad_temp_relu.copy()\n",
    "    grad_temp_relu[temp<0] = 0\n",
    "    grad_w1 = np.dot(X_.T, grad_temp)\n",
    "    grad_b1 = np.sum(grad_temp_relu)\n",
    "\n",
    "\n",
    "    # 更新权重, 对w1, w2, b1, b2进行更新\n",
    "    \"\"\" 这里写你的代码 \"\"\"  \n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "    b1 -= learning_rate * grad_b1\n",
    "    b2 -= learning_rate * grad_b2\n",
    "\n",
    "\n",
    "# 得到最终的w1, w2\n",
    "print('w1={} \\n w2={}'.format(w1, w2))\n",
    "print('b1={} \\n b2={}'.format(b1, b2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1=[[-0.62374308  1.14135394 -0.88785296 -1.89773221 -0.27683025 -1.46639794\n",
      "   1.05724103 -1.08826479 -0.92607025 -0.64098454]\n",
      " [-1.52798047  0.81103309  0.31094003  0.3741619   0.72654489 -1.44463324\n",
      "  -0.05756373 -0.97449373 -0.20399332  0.14010672]\n",
      " [ 0.43206531  0.06548046 -0.95035592 -0.59652834  1.32172812  0.17931638\n",
      "  -0.73599404 -0.18212068  0.49043687 -1.16558868]\n",
      " [ 0.44570295  1.24636472 -0.69584722 -1.09123592  1.70121207  1.75153055\n",
      "  -0.25824615 -0.11791384 -1.30996863 -1.06695388]\n",
      " [-0.85060318 -0.06957035 -1.5279229  -0.85089072  1.56429371 -0.17945639\n",
      "   0.35848927  0.41897746  0.52922041  0.54406083]\n",
      " [-0.38480779  1.14198607 -0.28505406  0.71548233  0.94638125 -0.16869284\n",
      "  -0.01001882 -0.69444202 -0.80984659 -1.98136405]\n",
      " [-0.30360292 -2.37556139  0.32902166  0.30893677  0.17537812 -0.75120136\n",
      "   0.55031583 -0.06192284  0.55109928  1.27803321]\n",
      " [ 1.23325753 -0.31850606  1.45411576 -2.06835909  1.22216335  0.34731555\n",
      "  -1.03355416  0.46232268 -0.43745485 -0.17579234]\n",
      " [ 1.06111862 -0.88212442 -2.14551468  0.89079146  0.37791879  1.53828913\n",
      "  -0.22239835  0.1801802  -0.45080429  1.68971291]\n",
      " [ 2.23720193  0.82853416 -0.36888665 -1.33041141 -0.75335521 -1.61216075\n",
      "   0.87217861 -1.28650343 -1.65160724 -0.51839898]\n",
      " [-0.32025751  0.60728877  0.34779643  0.62147135 -2.03020042  0.45538336\n",
      "  -0.31290908  1.20644307 -0.57936568  0.39624007]\n",
      " [ 0.8933933  -0.1784784   0.33781109 -0.64981689 -0.14957318  0.36782525\n",
      "  -1.11446585  0.62033624  1.2849888   1.92085149]\n",
      " [-0.79894644  1.42348819 -0.4027125   0.85738684  0.8205492   0.99277594\n",
      "   0.13679615  1.36369137  0.09801516  3.05757259]] \n",
      " w2=[[-0.81011324]\n",
      " [ 1.71277843]\n",
      " [-0.84457274]\n",
      " [-1.73756785]\n",
      " [-0.86573722]\n",
      " [ 0.53555891]\n",
      " [ 0.29640107]\n",
      " [ 1.00645537]\n",
      " [ 1.8123044 ]\n",
      " [ 0.54191223]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    使用numpy实现Boston房价预测\n",
    "    Step1 数据加载，来源sklearn中的load_boston\n",
    "    Step2 数据规范化，将X 采用正态分布规范化\n",
    "    Step3 初始化网络\n",
    "    Step4 定义激活函数，损失函数，学习率 epoch\n",
    "    Step5 循环执行：前向传播，计算损失函数，反向传播，参数更新\n",
    "    Step6 输出训练好的model参数，即w1, w2, b1, b2\n",
    "\"\"\" \n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "\n",
    "# 数据加载\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y = data['target']\n",
    "# 将y转化为矩阵的形式\n",
    "y = y.reshape(y.shape[0],1)\n",
    "\n",
    "# 数据规范化\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "\n",
    "\"\"\"\n",
    "    初始化网络参数\n",
    "    定义隐藏层维度，w1,b1,w2,b2\n",
    "\"\"\" \n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "w1 = np.random.randn(n_features, n_hidden)\n",
    "b1 = np.zeros(n_hidden)\n",
    "w2 = np.random.randn(n_hidden, 1)\n",
    "b2 = np.zeros(1)\n",
    "\n",
    "# relu函数\n",
    "def Relu(x):\n",
    "    \"\"\" 这里写你的代码 \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# 设置学习率\n",
    "learning_rate = 1e-6\n",
    "\n",
    "# 定义损失函数\n",
    "def MSE_loss(y, y_hat):\n",
    "    \"\"\" 这里写你的代码 \"\"\"\n",
    "    pass\n",
    "\n",
    "# 定义线性回归函数\n",
    "def Linear(X, W1, b1):\n",
    "    \"\"\" 这里写你的代码 \"\"\"\n",
    "    pass\n",
    "\n",
    "# 5000次迭代\n",
    "for t in range(5000):\n",
    "    # 前向传播，计算预测值y (Linear->Relu->Linear)\n",
    "    \"\"\" 这里写你的代码 \"\"\"\n",
    "\n",
    "\n",
    "    # 计算损失函数, 并输出每次epoch的loss\n",
    "    \"\"\" 这里写你的代码 \"\"\"\n",
    "\n",
    "\n",
    "    # 反向传播，基于loss 计算w1和w2的梯度\n",
    "    \"\"\" 这里写你的代码 \"\"\"    \n",
    "\n",
    "\n",
    "    # 更新权重, 对w1, w2, b1, b2进行更新\n",
    "    \"\"\" 这里写你的代码 \"\"\"    \n",
    "\n",
    "\n",
    "# 得到最终的w1, w2\n",
    "print('w1={} \\n w2={}'.format(w1, w2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
